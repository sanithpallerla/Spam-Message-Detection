{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16927df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 11:09:20.511285: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 11:09:33.394235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>641</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Message                                                            \\\n",
       "           count unique                                                top   \n",
       "Category                                                                     \n",
       "ham         4825   4516                             Sorry, I'll call later   \n",
       "spam         747    641  Please call our customer service representativ...   \n",
       "\n",
       "               \n",
       "         freq  \n",
       "Category       \n",
       "ham        30  \n",
       "spam        4  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "# import tensorflow_text as text    \n",
    "\n",
    "# !pip install --user tensorflow_text\n",
    "\n",
    "\n",
    "# !pip install tensorflow_hub\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data.csv')\n",
    "# \"C:\\Users\\akash\\Python_DL\\project_data\\Data.csv\"\n",
    "df.head(5)\n",
    "\n",
    "df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54740adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for Class spam:\n",
      "     Category                                            Message\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "5        spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "8        spam  WINNER!! As a valued network customer you have...\n",
      "9        spam  Had your mobile 11 months or more? U R entitle...\n",
      "11       spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "...       ...                                                ...\n",
      "5537     spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540     spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547     spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566     spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "\n",
      "[747 rows x 2 columns]\n",
      "\n",
      "DataFrame for Class ham:\n",
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "6         ham  Even my brother is not like to speak with me. ...\n",
      "...       ...                                                ...\n",
      "5565      ham                                       Huh y lei...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[4825 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separate data frames for individual classes (Class A and Class B)\n",
    "spam = df[df['Category'] == 'spam']\n",
    "ham = df[df['Category'] == 'ham']\n",
    "\n",
    "# Display the data frames\n",
    "print(\"DataFrame for Class spam:\")\n",
    "print(spam)\n",
    "\n",
    "print(\"\\nDataFrame for Class ham:\")\n",
    "print(ham)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af4b69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for Class ham (Downsampled):\n",
      "     Category                                            Message\n",
      "3714      ham  If i not meeting ü all rite then i'll go home ...\n",
      "1311      ham  I.ll always be there, even if its just in spir...\n",
      "548       ham                   Sorry that took so long, omw now\n",
      "1324      ham  I thk 50 shd be ok he said plus minus 10.. Did...\n",
      "3184      ham  Dunno i juz askin cos i got a card got 20% off...\n",
      "...       ...                                                ...\n",
      "4992      ham  We made it! Eta at taunton is 12:30 as planned...\n",
      "3117      ham                Uncle Abbey! Happy New Year. Abiola\n",
      "4975      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...\n",
      "3505      ham                          Will you be here for food\n",
      "1983      ham  Hey i will be late... i'm at amk. Need to drin...\n",
      "\n",
      "[747 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Downsample Class B to have the same number of samples as Class A\n",
    "ham_downsampled = ham.sample(n=len(spam), random_state=42)\n",
    "\n",
    "# Display the downsampled DataFrame for Class B\n",
    "print(\"DataFrame for Class ham (Downsampled):\")\n",
    "print(ham_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea66373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame:\n",
      "     Category                                            Message\n",
      "0        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "1        spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "2        spam  WINNER!! As a valued network customer you have...\n",
      "3        spam  Had your mobile 11 months or more? U R entitle...\n",
      "4        spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "...       ...                                                ...\n",
      "1489      ham  We made it! Eta at taunton is 12:30 as planned...\n",
      "1490      ham                Uncle Abbey! Happy New Year. Abiola\n",
      "1491      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...\n",
      "1492      ham                          Will you be here for food\n",
      "1493      ham  Hey i will be late... i'm at amk. Need to drin...\n",
      "\n",
      "[1494 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "all_downsampled = pd.concat([spam, ham_downsampled], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(\"Concatenated DataFrame:\")\n",
    "print(all_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ef4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message  Label\n",
      "0        spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
      "1        spam  FreeMsg Hey there darling it's been 3 week's n...      1\n",
      "2        spam  WINNER!! As a valued network customer you have...      1\n",
      "3        spam  Had your mobile 11 months or more? U R entitle...      1\n",
      "4        spam  SIX chances to win CASH! From 100 to 20,000 po...      1\n",
      "...       ...                                                ...    ...\n",
      "1489      ham  We made it! Eta at taunton is 12:30 as planned...      0\n",
      "1490      ham                Uncle Abbey! Happy New Year. Abiola      0\n",
      "1491      ham  Aiyo u so poor thing... Then u dun wan 2 eat? ...      0\n",
      "1492      ham                          Will you be here for food      0\n",
      "1493      ham  Hey i will be late... i'm at amk. Need to drin...      0\n",
      "\n",
      "[1494 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {'spam': 1, 'ham': 0}\n",
    "all_downsampled['Label'] = all_downsampled['Category'].apply(lambda x: label_mapping[x])\n",
    "\n",
    "# Display the updated DataFrame with the 'Label' column\n",
    "print(all_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b066be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape - X_train: (1195, 1) y_train: (1195,)\n",
      "Testing set shape - X_test: (299, 1) y_test: (299,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Features (X) are all the columns except 'Category' and 'Label'\n",
    "X = all_downsampled.drop(columns=['Category', 'Label'])\n",
    "\n",
    "# Labels (y) are contained in the 'Label' column\n",
    "y = all_downsampled['Label']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training set shape - X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"Testing set shape - X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7402dd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Bored housewives! Chat n date now! 0871750.77....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>This is the 2nd time we have tried to contact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>ALRITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Promotion Number: 8714714 - UR awarded a City ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Message\n",
       "532   Bored housewives! Chat n date now! 0871750.77....\n",
       "534   This is the 2nd time we have tried to contact ...\n",
       "1108                                             ALRITE\n",
       "490   Promotion Number: 8714714 - UR awarded a City ...\n",
       "933   I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5023c6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 11:10:12.731347: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Downloading the bert models for pre processing and encoding\n",
    "\n",
    "\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97cf0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a7d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " text (InputLayer)           [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)    {'input_type_ids': (None,    0         ['text[0][0]']                \n",
      "                             128),                                                                \n",
      "                              'input_mask': (None, 128)                                           \n",
      "                             , 'input_word_ids': (None,                                           \n",
      "                              128)}                                                               \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)  {'pooled_output': (None, 7   1094822   ['keras_layer[0][0]',         \n",
      "                             68),                         41         'keras_layer[0][1]',         \n",
      "                              'sequence_output': (None,              'keras_layer[0][2]']         \n",
      "                              128, 768),                                                          \n",
      "                              'encoder_outputs': [(None                                           \n",
      "                             , 128, 768),                                                         \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768)],                                                  \n",
      "                              'default': (None, 768)}                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 768)                  0         ['keras_layer_1[0][13]']      \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 1)                    769       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109483010 (417.64 MB)\n",
      "Trainable params: 769 (3.00 KB)\n",
      "Non-trainable params: 109482241 (417.64 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935b1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd158a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 467s 12s/step - loss: 0.6734 - accuracy: 0.5900\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 445s 12s/step - loss: 0.5270 - accuracy: 0.7983\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 451s 12s/step - loss: 0.4473 - accuracy: 0.8619\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 628s 17s/step - loss: 0.3988 - accuracy: 0.8753\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 683s 18s/step - loss: 0.3629 - accuracy: 0.8854\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 312s 8s/step - loss: 0.3366 - accuracy: 0.8946\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 409s 11s/step - loss: 0.3185 - accuracy: 0.8996\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 393s 10s/step - loss: 0.2941 - accuracy: 0.9105\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 415s 11s/step - loss: 0.2917 - accuracy: 0.9155\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 403s 11s/step - loss: 0.2787 - accuracy: 0.9071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fec758af820>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df626b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 96s 9s/step - loss: 0.3127 - accuracy: 0.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.312650591135025, 0.8896321058273315]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87cd104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.83589005],\n",
       "       [0.87188363],\n",
       "       [0.84463155],\n",
       "       [0.2289247 ],\n",
       "       [0.13511556]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "    'Reply to win Â£100 weekly! Where will the 2006 FIFA World Cup be held? Send STOP to 87239 to end service',\n",
    "    'You are awarded a SiPix Digital Camera! call 09061221061 from landline. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16 . p pÂ£3.99',\n",
    "    'it to 80488. Your 500 free text messages are valid until 31 December 2005.',\n",
    "    'Hey Sam, Are you coming for a cricket game tomorrow',\n",
    "    \"Why don't you wait 'til at least wednesday to see if you get your .\"\n",
    "]\n",
    "\n",
    "\n",
    "model.predict(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99f03c33-c6c4-4ef9-8f86-86d82bc41771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trail_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trail_1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('trail_1', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db9083cf-8276-4664-bf08-160f21d28490",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: spam_text_classifier/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reloaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspam_text_classifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DeepLearning/Final Project/fp/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:858\u001b[0m, in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[1;32m    857\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[0;32m--> 858\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/DeepLearning/Final Project/fp/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:963\u001b[0m, in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[1;32m    959\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[1;32m    960\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[1;32m    961\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[1;32m    962\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 963\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    967\u001b[0m   metrics\u001b[38;5;241m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[0;32m~/DeepLearning/Final Project/fp/lib/python3.10/site-packages/tensorflow/python/saved_model/loader_impl.py:58\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     61\u001b[0m       path_helpers\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[1;32m     62\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[1;32m     63\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[0;32m~/DeepLearning/Final Project/fp/lib/python3.10/site-packages/tensorflow/python/saved_model/loader_impl.py:116\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    117\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: spam_text_classifier/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "reloaded_model = tf.saved_model.load('spam_text_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59f084-000e-4d3f-820d-6a904477cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_results = tf.sigmoid(reloaded_model(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3432c12-a927-4e3c-841a-307cdd9182e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results from the saved model:')\n",
    "type(reloaded_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c474b0-f7df-46a5-990a-269e1b99e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = reloaded_results.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42674a6c-32b2-4980-be88-d4b252adef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce3b45-2e71-4782-bf0e-c9a5c5e31919",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = [\n",
    "    'Get assured prize for helping Tom in MI Challenge ',\n",
    "    'Everything you need for outrageously effective odor control',\n",
    "    '5 minutes. 250+ Data projects. 1-1 session with an advisor',\n",
    "    'Nah, I dont think',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562144f-4c8c-4b90-ba30-985588bafe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e2754-4907-4636-afc8-e192dde033a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
